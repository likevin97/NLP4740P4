{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline\n",
    "\n",
    "Implimenting as baseline model to determine if the question is answerable based on the occurance of $target$ words in the context of the parent paragraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import json\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified question\n",
    "def getSimpleQuestion(question):\n",
    "    text = nltk.word_tokenize(question)\n",
    "    words = nltk.pos_tag(text)\n",
    "    less_words = [wt for (wt, tag) in words if tag not in [\"CC\",\"DT\",\"EX\",\"IN\",\"LS\",\"POS\",\"TO\",\".\",\"\\\\\",\",\",\":\",\"(\",\")\"]]\n",
    "    # less_words = [wt for (wt, tag) in words if tag in [\"NN\",\"NNS\", \"NNP\",\"NNPS\"]]\n",
    "    return less_words\n",
    "\n",
    "def countWordsInParagraph(context):\n",
    "    wordList = nltk.word_tokenize(context)\n",
    "    counts = Counter(wordList)\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"development.json\")\n",
    "j = json.load(file)\n",
    "predictions = {} #id:value\n",
    "\n",
    "for data in j['data']:\n",
    "    t = data[\"title\"]\n",
    "    title = t.split()\n",
    "    for paragraph in data[\"paragraphs\"]:\n",
    "        context = paragraph[\"context\"]\n",
    "        dic = countWordsInParagraph(context)\n",
    "        \n",
    "        for q in paragraph[\"qas\"]:\n",
    "            question = q[\"question\"]\n",
    "            ids = q[\"id\"]\n",
    "            \n",
    "            new_question = getSimpleQuestion(question)\n",
    "            total = 0\n",
    "            for word in new_question:\n",
    "                if word in dic:\n",
    "                    total+= dic[word]\n",
    "\n",
    "            if total > 2:\n",
    "                predictions[ids] = 1\n",
    "            else:\n",
    "                predictions[ids] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output.json', 'w') as outfile:  \n",
    "    json.dump(predictions, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
